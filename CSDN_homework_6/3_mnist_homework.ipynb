{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_mnist_homework.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "uaTVfJqyXlna",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"A very simple MNIST classifier.\n",
        "See extensive documentation at\n",
        "https://www.tensorflow.org/get_started/mnist/beginners\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "FLAGS = None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d76ATdJmXlne",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "2b47d33e-2ef0-46af-e9b2-1efef4c4f243",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532831691464,
          "user_tz": -480,
          "elapsed": 2665,
          "user": {
            "displayName": "Zichen Qi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112431834484485515110"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "data_dir = '/tmp/tensorflow/mnist/input_data'\n",
        "mnist = input_data.read_data_sets(data_dir, one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-7e828717a4ff>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JUqyt1Zb_2UV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.set_random_seed(1)\n",
        "seed = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDyosOvmtBQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "两层神经网络"
      ]
    },
    {
      "metadata": {
        "id": "IWKR5HUsXlnh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d440acd4-cbb9-445c-80c7-c0637e83a498",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532835583365,
          "user_tz": -480,
          "elapsed": 11291,
          "user": {
            "displayName": "Zichen Qi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112431834484485515110"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "x = tf.placeholder(tf.float32, [None,784])\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 256],stddev=np.sqrt(2.0 / 784),seed =1)) #对每层的每个神经元神经元初始化，落在均值附近\n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "Z1 = tf.add(tf.matmul(x,W1),b1) \n",
        "A1 = tf.nn.relu(Z1) \n",
        "W2 = tf.Variable(tf.truncated_normal([256, 10],stddev=np.sqrt(2.0 / 256),seed = 1))\n",
        "b2 = tf.Variable(tf.zeros([10]))\n",
        "Z2 = tf.add(tf.matmul(A1,W2),b2)\n",
        "\n",
        "y_ = tf.placeholder(tf.float32, [None,10])\n",
        "\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Z2))\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
        "\n",
        "sess = tf.Session()\n",
        "init_op = tf.global_variables_initializer()\n",
        "sess.run(init_op)\n",
        "\n",
        "# Train\n",
        "for _ in range(3000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
        "  \n",
        "   # Test trained model\n",
        "correct_prediction = tf.equal(tf.argmax(Z2, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
        "                                      y_: mnist.test.labels}))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RLjYeLhSXlny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "将这个模型优化至98%以上的准确率。\n",
        "Hint：\n",
        "- 多隐层\n",
        "- 激活函数\n",
        "- 正则化\n",
        "- 初始化\n",
        "- 摸索一下各个超参数\n",
        "  - 隐层神经元数量\n",
        "  - 学习率\n",
        "  - 正则化惩罚因子\n",
        "  - 最好每隔几个step就对loss、accuracy等等进行一次输出，这样才能有根据地进行调整"
      ]
    },
    {
      "metadata": {
        "id": "Yf3gMSQOtMP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "两层神经网络+正则"
      ]
    },
    {
      "metadata": {
        "id": "IrN_eIBjsOze",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a8225f9-9a66-40a9-e511-323986b3a9f5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532836669302,
          "user_tz": -480,
          "elapsed": 13386,
          "user": {
            "displayName": "Zichen Qi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112431834484485515110"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "x = tf.placeholder(tf.float32, [None,784])\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 256],stddev=np.sqrt(2.0 / 784),seed =1)) \n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "Z1 = tf.add(tf.matmul(x,W1),b1) \n",
        "A1 = tf.nn.relu(Z1) \n",
        "W2 = tf.Variable(tf.truncated_normal([256, 10],stddev=np.sqrt(2.0 / 256),seed = 1))\n",
        "b2 = tf.Variable(tf.zeros([10]))\n",
        "Z2 = tf.add(tf.matmul(A1,W2),b2)\n",
        "\n",
        "\n",
        "y_ = tf.placeholder(tf.float32, [None,10])\n",
        "\n",
        "beta = 0.0001\n",
        "reg = tf.nn.l2_loss(W1)+tf.nn.l2_loss(W2)\n",
        "\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Z2)+ beta*reg)\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
        "\n",
        "sess = tf.Session()\n",
        "init_op = tf.global_variables_initializer()\n",
        "sess.run(init_op)\n",
        "\n",
        "# Train\n",
        "for _ in range(3000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
        "  \n",
        "   # Test trained model\n",
        "correct_prediction = tf.equal(tf.argmax(Z2, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
        "                                      y_: mnist.test.labels}))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B0lRf4EE4b6N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "四层神经网络(由于数据量太小，随着神经网络层数的增加，需要的训练数据越多，对于这个数据集一层隐层是最合适的)"
      ]
    },
    {
      "metadata": {
        "id": "_u96kOLe4abh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "648d4d4f-a26b-4710-be30-3c12ef337d10",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532837667677,
          "user_tz": -480,
          "elapsed": 82779,
          "user": {
            "displayName": "Zichen Qi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112431834484485515110"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "x = tf.placeholder(tf.float32, [None,784])\n",
        "\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 256],stddev=np.sqrt(2.0 / 256),seed =1))\n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "Z1 = tf.add(tf.matmul(x,W1),b1) \n",
        "A1 = tf.nn.relu(Z1) \n",
        "\n",
        "W2 = tf.Variable(tf.truncated_normal([256, 128],stddev=np.sqrt(2.0 / 128),seed =1))\n",
        "b2 = tf.Variable(tf.zeros([128]))\n",
        "Z2 = tf.add(tf.matmul(A1,W2),b2)\n",
        "A2 = tf.nn.relu(Z2)\n",
        "\n",
        "W3 = tf.Variable(tf.truncated_normal([128, 64],stddev=np.sqrt(2.0 / 64),seed =1))\n",
        "b3 = tf.Variable(tf.zeros([64]))\n",
        "Z3 = tf.add(tf.matmul(A2,W3),b3)\n",
        "A3 = tf.nn.relu(Z3)\n",
        "\n",
        "W4 = tf.Variable(tf.truncated_normal([64, 10],stddev=np.sqrt(2.0 / 10),seed =1))\n",
        "b4 = tf.Variable(tf.zeros([10]))\n",
        "Z4 = tf.add(tf.matmul(A3,W4),b4)\n",
        "\n",
        "beta = 0.001\n",
        "reg = tf.nn.l2_loss(W1)+tf.nn.l2_loss(W2)+tf.nn.l2_loss(W3)+tf.nn.l2_loss(W4)\n",
        "\n",
        "y_ = tf.placeholder(tf.float32, [None,10])\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Z4)+ beta*reg)\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
        "\n",
        "sess = tf.Session()\n",
        "init_op = tf.global_variables_initializer()\n",
        "sess.run(init_op)\n",
        "\n",
        "# Train\n",
        "for _ in range(3000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100) \n",
        "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
        "  \n",
        "    # Test trained model\n",
        "correct_prediction = tf.equal(tf.argmax(Z4, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
        "                                      y_: mnist.test.labels}))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LMEAm4DWQe2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "调整学习率（手动调节）"
      ]
    },
    {
      "metadata": {
        "id": "H3alvLUYQfi2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2645dc31-902b-41c8-d570-96e337053525",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532837984887,
          "user_tz": -480,
          "elapsed": 11462,
          "user": {
            "displayName": "Zichen Qi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "112431834484485515110"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "x = tf.placeholder(tf.float32, [None,784])\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 256],stddev=np.sqrt(2.0 / 784),seed =1)) #对每层的每个神经元神经元初始化，落在均值附近\n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "Z1 = tf.add(tf.matmul(x,W1),b1) \n",
        "A1 = tf.nn.relu(Z1) \n",
        "W2 = tf.Variable(tf.truncated_normal([256, 10],stddev=np.sqrt(2.0 / 256),seed = 1))\n",
        "b2 = tf.Variable(tf.zeros([10]))\n",
        "Z2 = tf.add(tf.matmul(A1,W2),b2)\n",
        "\n",
        "y_ = tf.placeholder(tf.float32, [None,10])\n",
        "\n",
        "cross_entropy = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Z2))\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(cross_entropy)\n",
        "\n",
        "sess = tf.Session()\n",
        "init_op = tf.global_variables_initializer()\n",
        "sess.run(init_op)\n",
        "\n",
        "# Train\n",
        "for _ in range(3000):\n",
        "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
        "  \n",
        "   # Test trained model\n",
        "correct_prediction = tf.equal(tf.argmax(Z2, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
        "                                      y_: mnist.test.labels}))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9736\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}